# ğŸ“Œ InstaSearch - Elasticsearch + Python å…¨æ–‡æª¢ç´¢å°ˆæ¡ˆ

## ğŸ”¥ ç°¡ä»‹
InstaSearch æ˜¯ä¸€å€‹åŸºæ–¼ **Elasticsearch** çš„å…¨æ–‡æª¢ç´¢ç³»çµ±ï¼Œæä¾› **Streamlit** ç¶²ç«™ä»‹é¢ä¸¦é€²è¡Œæ–‡æœ¬æœç´¢ã€‚æ­¤å°ˆæ¡ˆé©ç”¨æ–¼å­¸ç¿’ **Elasticsearch æœç´¢æŠ€è¡“**ï¼Œä¸¦æä¾›Python API ä¾†è®€å–å’Œè™•ç† IG æ–‡ç« æˆ–å…¶ä»–æ–‡æœ¬æ•¸æ“šã€‚

---
### ç¶²ç«™ä»‹é¢
![ç¶²ç«™ä»‹é¢](imgs/demo.png)
### ElasticSearchç¤ºæ„è³‡æ–™(Kibanaä»‹é¢)
![ç¶²ç«™ä»‹é¢](imgs/demo2.png)
---

## å®‰è£èˆ‡è¨­å®š

### **1ï¸âƒ£ å®‰è£ Elasticsearch & Kibana**
**ä½¿ç”¨ Docker Compose å•Ÿå‹•æœå‹™ï¼š**
```bash
docker-compose up -d
```

## ä¸‹è¼‰ç¯„ä¾‹IGæª”(IGæ–‡ç« ã€å½±åƒã€notebooks)
```bash
git lfs pull
```

**é©—è­‰ Elasticsearch æ˜¯å¦é‹è¡Œï¼š**
```bash
curl http://localhost:9200
```

**é©—è­‰ Kibana æ˜¯å¦é‹è¡Œï¼š**
æ‰“é–‹ç€è¦½å™¨ä¸¦è¨ªå•ï¼š ğŸ‘‰ [http://localhost:5601](http://localhost:5601)

### **2ï¸âƒ£ å®‰è£ Python Elasticsearch å®¢æˆ¶ç«¯**
```bash
pip install elasticsearch
```

### **3ï¸âƒ£ å»ºç«‹ç´¢å¼•ä¸¦æ’å…¥æ¸¬è©¦æ–‡æœ¬**
```python
from elasticsearch import Elasticsearch
import datetime

# é€£æ¥ Elasticsearch
es = Elasticsearch("http://localhost:9200")

# å»ºç«‹ç´¢å¼•
index_name = "text_experiment"
if es.indices.exists(index=index_name):
    es.indices.delete(index=index_name)

es.indices.create(index=index_name, body={
    "settings": {"number_of_shards": 1, "number_of_replicas": 0},
    "mappings": {
        "properties": {
            "title": {"type": "text"},
            "content": {"type": "text"},
            "tags": {"type": "keyword"},
            "created_at": {"type": "date"}
        }
    }
})

# æ’å…¥æ¸¬è©¦æ–‡æœ¬
doc = {
    "title": "Elasticsearch æ¸¬è©¦æ–‡æª”",
    "content": "é€™æ˜¯ä¸€å€‹æ¸¬è©¦ Elasticsearch æ’å…¥èˆ‡åˆªé™¤æ–‡æœ¬çš„ç¯„ä¾‹ã€‚",
    "tags": ["search", "test"],
    "created_at": datetime.datetime.now()
}
res = es.index(index=index_name, body=doc)
print(f"âœ… æ–‡æœ¬å·²å¯«å…¥ï¼ŒID: {res['_id']}")
```

### **4ï¸âƒ£ æœç´¢æ–‡æœ¬**
```python
query = {"query": {"match": {"content": "æ¸¬è©¦"}}}
response = es.search(index=index_name, body=query)
for hit in response["hits"]["hits"]:
    print(f"ğŸ“„ {hit['_source']['title']} (ID: {hit['_id']})")
```

### **5ï¸âƒ£ åˆªé™¤ç´¢å¼•**
```python
es.indices.delete(index=index_name)
print(f"ğŸ—‘ï¸ ç´¢å¼• '{index_name}' å·²åˆªé™¤")
```

---

## ğŸ“Œ å°ˆæ¡ˆçµæ§‹
```bash
InstaSearch/
â”‚â”€â”€ data/                      # æœ¬æ©Ÿå„²å­˜ Elasticsearch ç´¢å¼•çš„ç›®éŒ„
â”‚â”€â”€ docker-compose.yml         # Docker è¨­å®šæ–‡ä»¶
â”‚â”€â”€ streamlit_app/             # Python ç¨‹å¼ç¢¼ç›®éŒ„
â”‚â”€â”€ notebook/                  # ESè³‡æ–™æ–°åˆªä¿®notebookè…³æœ¬
â”‚â”€â”€ README.md                  # æœ¬æ–‡ä»¶
```

---

## ğŸ› ï¸ å¸¸è¦‹å•é¡Œ
### **1ï¸âƒ£ Elasticsearch/Kibana ç„¡æ³•å•Ÿå‹•ï¼Ÿ**
è«‹æª¢æŸ¥æ˜¯å¦æœ‰å…¶ä»– Elasticsearch åŸ·è¡Œä¸­ï¼š
```bash
docker ps | grep elasticsearch
```
å¦‚æœæœ‰èˆŠçš„å®¹å™¨ï¼Œè«‹å…ˆåˆªé™¤ï¼š
```bash
docker-compose down -v
```
ç„¶å¾Œé‡æ–°å•Ÿå‹•ï¼š
```bash
docker-compose up -d
```

---

## ğŸ“¢ è¯çµ¡ä½œè€…
å¦‚æœä½ æœ‰ä»»ä½•å•é¡Œæˆ–æ”¹é€²å»ºè­°ï¼Œè«‹è¯çµ¡ [ä½ çš„ GitHub](https://github.com/yourname)ï¼

ğŸš€ **å¿«ä¾†è©¦è©¦ Elasticsearch çš„å¼·å¤§å…¨æ–‡æª¢ç´¢åŠŸèƒ½å§ï¼**
